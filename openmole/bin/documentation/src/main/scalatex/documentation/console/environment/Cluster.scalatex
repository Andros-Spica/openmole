
@import documentation.Objects._


@sect{Batch systems}
  Many distributed computing environments offer @a("batch processing", href := "https://en.wikipedia.org/wiki/Batch_processing") capabilities. OpenMOLE supports most of the batch systems. Batch systems generally work by exposing an entry point on which the user can log on and submit jobs. OpenMOLE accesses this entry point using SSH.

  @p The first thing to do to be able to use you batch system with OpenMOLE is to provide your authentication information to OpenMOLE.

  @part.SSHAuthentication()

  @sect{PBS / Torque}
    @a("PBS", href :="http://en.wikipedia.org/wiki/Portable_Batch_System") is a venerable batch system for clusters. You may use a PBS computing environment as follow:
    @br @hl.openmole("""
    import org.openmole.plugin.environment.pbs._

    val env =
      PBSEnvironment(
        "login",
        "machine.domain"
      )""")

   @p @provideOptions:
   @ul
     @li{@port,}
     @li{@workDirectory,}
     @li{@queue,}
     @li{@wallTime,}
     @li{@memory,}
     @li{@openMOLEMemory,}
     @li{@threads.}
  @sect{SGE}
    To delegate some computation load to a @a("SGE", href := "https://en.wikipedia.org/wiki/Oracle_Grid_Engine") based cluster you can use the SGEEnvironment as follow:
    @br @hl.openmole("""
    import org.openmole.plugin.environment.sge._

    val env =
      SGEEnvironment(
        "login",
        "machine.domain"
      )""")
    @p @provideOptions:
    @ul
      @li{@port,}
      @li{@workDirectory,}
      @li{@queue,}
      @li{@wallTime,}
      @li{@memory,}
      @li{@openMOLEMemory,}
      @li{@threads.}
  @sect{SLURM}
    To delegate some computation load to a @a("SLURM", href := "https://en.wikipedia.org/wiki/Simple_Linux_Utility_for_Resource_Management") based cluster you can use the SLURM environment as follow:
    @br @hl.openmole("""
    import org.openmole.plugin.environment.slurm._
    import fr.iscpif.gridscale.slurm.Gres // only when using GRES Scheduling

    val env =
      SLURMEnvironment(
        "login",
        "machine.domain",
        // optional parameters
        gres = List( Gres("resource", 1) ),
        constraints = List("constraint1", "constraint2")
      )""")
    @p @provideOptions:
    @ul
      @li{@port,}
      @li{@workDirectory,}
      @li{@queue,}
      @li{@wallTime,}
      @li{@memory,}
      @li{@openMOLEMemory,}
      @li{@threads,}
      @li{qos: Quality of Service (QOS) as defined in the Slurm database}
      @li{gres: a list of Generic Resource (GRES) requested. A Gres is a pair defined by the name of the resource and the number of resources requested (scalar).}
      @li{constraints: a list of Slurm defined constraints which selected nodes must match.}
  @sect{Condor}
    To delegate some computation load to a @a("Condor", href := "https://en.wikipedia.org/wiki/HTCondor") condor based cluster you can use the CondorEnvironment as follow:
    @br @hl.openmole("""
    import org.openmole.plugin.environment.condor._

    val env =
      CondorEnvironment(
        "login",
        "machine.domain"
      )""")
    @p @provideOptions:
    @ul
      @li{@port,}
      @li{@workDirectory,}
      @li{@memory,}
      @li{@openMOLEMemory,}
      @li{@threads.}
  @sect{OAR}
    To delegate some computation load to an @a("OAR", href := "http://oar.imag.fr/dokuwiki/doku.php") cluster, you can do a follow:
    @br @hl.openmole("""
    import org.openmole.plugin.environment.oar._

    val env =
      OAREnvironment(
        "login",
        "machine.domain"
      )""")
    @p @provideOptions:
    @ul
      @li{@port,}
      @li{@workDirectory,}
      @li{@queue,}
      @li{@wallTime,}
      @li{@openMOLEMemory,}
      @li{@threads,}
      @li{core: number of core allocated for each job,}
      @li{cpu: number of CPUs allocated for each job.}
