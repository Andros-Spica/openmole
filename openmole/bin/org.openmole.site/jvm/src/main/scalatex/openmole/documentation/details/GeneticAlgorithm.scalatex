@import org.openmole.site.tools._
@import org.openmole.site._


@def model = """
  //model inputs
  val x = Val[Double]
  val y = Val[Double]
  //model outputs
  val o1 = Val[Double]
  val o2 = Val[Double]

  val model =
    ScalaTask("val o1 = x; val o2 = y") set (
      inputs += (x, y),
      outputs += (o1, o2)
    )
"""




@h1{Genetic Algorithms in OpenMOLE}

@p

Trucs à dire
@br
optimization problem  => NSGA2
@br
DIstributed environments=>  islands
@br
Diversity => GA with novelty incentive
@br

Stochasticity => balance exploration pour nouvelles solutions et réplications des simulations






@h2
    Automatic parameters calibration methods using Genetic Algorithms


@p
    OpenMOLE provides advanced methods to help you calibrate your model.
    These methods automatically generate workflows to explore your model's parameter space towards the best parameter
    set according to a previously defined @b{goal} (or @b{objective} or @b{criterion}) .
    This is commonly addressed in literature as a calibration/optimization methods.

@p


@h3
    Context
@p
    Calibration methods explore the parameter space of a simulation model, looking for parameter sets that will produce
    outputs  that reach one or several given @b{objectives}.

    Usually, objectives are quantities -computed from model outputs- that have to be minimized or maximized.
    It's a quantification of the characteristics of what is a @i{good model output} according to what
    you're looking for.

@br

    One common use case is when you want to fit some data. Objective function could be
    a distance function between simulation results and data ; a classical example is the Squared Error function.
@br

    If you want your model to reproduce several characteristics (sometimes called stylised facts), you need
    several objectives, each of them quantifying the closeness, or similarity between your model outputs
    and the characteristics you want to reproduce.

@br
Un peu relou cet exemple finalement TODO à virer ?
    For example, if your ideal dynamic is such that one of your model outputs reaches a certain value V
    after a certain time T, in a linear way, you want to reach  three distinct objectives :
    @ul
        @li
            the given value V
        @li
            the given time T
        @li
            the linear progression of the model output time-serie from (0,0) to (T, V)

    Corresponding function to minimize could be the difference between the target value and the output at time T,
    the difference between target time  T and the simulation time at which the value V is reached by the model output,
    and the quality of the linear adjustment of the model output time serie from 0 to T.

@p

    To calibrate your model with OpenMOLE, you need to define:

     @ul
        @li
            the @b{genome} of your model, i.e. the parameters to be calibrated. They are the dimensions of the parameter
             space that will be explored by the genetic algorithm.
        @li
            the @b{objectives} you want to reach, expressed as a variables to be @b{minimized}.
        @li
            a @b{termination criterion}, to stop the method

@h3

    Dummy Model Optimization Example

@p
    This workflow optimises a dummy model using the generational NSGA II multi-objective algorithm. You can replace the instances of @i{model} by your own model and adapt the variation range of its input variables. If you're not familiar with parameter tuning using Genetic Algorithms (GA), you should first consult the @a("tutorial explaining how to calibrate a NetLogo model with a GA", href := DocumentationPages.root.tutorial.netLogoGA.file).

    @br @hl.openmole(s"""
  $model

  // Construction of the workflow orchestrating the genetic algorithm
  // termination is the termination criterion, here it runs for 100 generations. A time limit could be set as an
  // alternative by replacing 100 by 1 hour (hour is a duration type understood by OpenMOLE).
  // the parallelism specifies how many evaluation are concurrently submitted to the execution environment
  val evolution =
    SteadyStateEvolution(
      // Definition of the optimisation algorithm
      // mu is the size of the population
      // genome is the inputs prototype and their variation ranges
      // objectives are the objectives to minimise
      algorithm =
        NSGA2(
          mu = 100,
          genome = Seq(x in (0.0, 1.0), y in (0.0, 1.0)),
          objectives = Seq(o1, o2)
        ),
        evaluation = model,
        parallelism = 10,
        termination = 100
    )


  // Definition of a hook to save the population of solutions to /tmp/evolution on the local machine running OpenMOLE
  val savePopulation = SavePopulationHook(evolution, workDirectory / "evolution/")

  // Construction of the complete workflow with the execution environment, and the hook.
  // Here the generated workflow will run using 4 threads of the local machine.
  (evolution hook savePopulation on LocalEnvironment(4))""")

@br

Notice that the objectives are given as a sequence of model outputs variables to @b{minimize}.
So if you want to reach specific target values, like Pi and 42  you should have written your objectives as

@hl.openmole("""objectives = Seq(math.abs(o1-> math.Pi), math.abs(o2->42))""")
@br

TODO checker syntaxe et écriture d'une task dédiée avant d'écrire ça  o1 -> 22 , o2 -> math.Pi
Il faut pouvoir facilement définir les target values : je veux optimiser mon modèle pour qu'il me donne 25 , il faut que
 ce soit limpide à la lecture du script oms


Obviously, maximization problem are  performed by taking the opposite of variables as objectives.

@h3
    Scaling Up the calibration


  @p For distributed environments the island distribution scheme is well adapted. Islands of population evolve for a
  while on a remote node. When an island is finished, its final population is merged back into a global archive.
  A new island is then generated until the termination criterion: i.e. the total number of islands to generate is met.
  Islands can be used as follows:

  @br @hl.openmole("""
  val evolution =
    SteadyStateEvolution(
      // Definition of the optimisation algorithm
      // mu is the size of the population
      // genome is the inputs prototype and their variation ranges
      // objectives are the objectives to minimise
      algorithm =
        NSGA2(
          mu = 100,
          genome = Seq(x in (0.0, 1.0), y in (0.0, 1.0)),
          objectives = Seq(o1, o2)
        ),
      evaluation = model,
      termination = 100
    )

  // Generate a workflow that orchestrates 100 concurrent islands.
  // The workflow stops when 10,000 islands have completed.
  val island =
    IslandEvolution(
      evolution,
      parallelism = 100,
      termination = 10000
    )

  // Definition of a hook to save the population of solutions on the local machine running OpenMOLE
  val savePopulation = SavePopulationHook(island, workDirectory / "evolution")

  // Construction of the complete mole with the execution environment, and the hook.
  // Here the generated workflow will run using 4 threads of the local machine.
  (island on LocalEnvironment(4) hook savePopulation)""", header = model)

  @p Calibration of stochastic models leads to noisy fitness functions. An efficient strategy to deal with such
  fitness functions is implemented in OpenMOLE. This strategy automatically balances the need for replications and
  the discovery of new solutions. In case you want to explore a stochastic model with a genetic algorithm you can do:

  @br @hl.openmole("""
  val seed = Val[Long]

  val evolution =
    SteadyStateEvolution(
      // Definition of the optimisation algorithm
      // mu is the size of the population
      // genome is the inputs prototype and their variation ranges
      // objectives are the objectives to minimise
      algorithm =
        NSGA2(
          mu = 100,
          genome = Seq(x in (0.0, 1.0), y in (0.0, 1.0)),
          objectives = Seq(o1, o2),
          // OpenMOLE provide a seed for your stochastic model to use (it is optional)
          // 20% of the evaluations are used for replicating existing solutions
          // 100 replication are stored at max for each individual
          stochastic = Stochastic(seed = seed, reevaluate = 0.2, replications = 100)
        ),
      evaluation = model,
      termination = 100
    )""", header = model)




