@import org.openmole.site.stylesheet._
@import org.openmole.site.Resource._
@import org.openmole.site._
@import org.openmole.site.tools._
@import org.openmole.site.Environment._



@b{Design of Experiments} (DoE) is the art of setting up an experimentation. In a model simulation context,
it boils down to declare the inputs under study (most of the time, they're parameters) and the values they will take, for a batch of several simulations, with the idea of revealing a property of the model (e.g. sensitivity).
Even if there are several state-of-the-art DoE methods implemented in OpenMOLE, we recommend to focus on OpenMOLE
new methods:  PSE, and Calibration and Profiles  which have been thought to improve the drawbacks of the classical methods.

@br
@br

Your model inputs can be sampled in the traditional way, by using @a("grid (or regular)  sampling" , href:=shared.otherDoEMenu.basicSampling) , or by @a("sampling uniformly", href:=shared.otherDoEMenu.basicSampling) inside their domain.
@br
For higher dimension input space, specific statistics techniques like @a("Latin Hypercube Sampling and SobolSequence", href:=shared.otherDoEMenu.LHSSobol) are available.
@br
By defining your own exploration task on @a("several types of input", href:= shared.otherDoEMenu.severalInputs), you will be able to highlight some of your model inner properties like those revealed by @a("sensitivity analysis", href:=shared.otherDoEMenu.sensitivityAnalysis), as shown in a toy example on a @a("real world example", href:=shared.otherDoEMenu.sensitivityFireModel)



@sect{@shared.otherDoEMenu.basicSampling }
    @br
    For a reasonable number of dimension and discretisation quanta (steps) values, complete sampling (or grid sampling)  consists in producing every combination of
    the inputs possibles values, given their bounds and quanta of discretisation.
    @br
    @br
    @Resource.rawFrag(Resource.img.completeID)
    @br
    @b{Method scores:}
    @br
    Regular sampling or Uniform Sampling are quite good for a first Input Space exploration when you don't know anything
    about its structure yet.
    Since it samples from the input space, the collected values from the model executions will reveal the output values
    obtained for "evenly spaced" inputs.
    Sure it's not perfect, but still , it gives a little bit of insights about model sensitivity (as input values vary
    within their domain) and if the output are fitness, it may present a little bit of optimization information (as the zone in which the fitness could be
    minimized).
    @br The sampling does not reveal anything about the output space structure, as there is no reason than evenly spaced inputs lead
    to evenly spaced outputs.
    Basic sampling is hampered by input space dimensionality as high dimension spaces need a lot of samples to be covered.
    @hr

    @br
    Complete sampling is declared as an @b{ExplorationTask}, where the bounds and discretisation quantum of each input to vary  are declared
    using the following syntax :

    @br @br
    @hl.openmole("""
       val input_i = Val[Int]
       val input_j = Val[Double]

       val exploration =
         ExplorationTask (
           (input_i in (0 to 10 by 2)) x
           (input_j in (0.0 to 5.0 by 0.5))
         )""", name = "cartesian product for sensitivity")

    In this example ExplorationTask, two inputs are varying at the same time, using the cartesian product, see the  @sect.ref{Variation of several inputs}
    to get more details on the input combination.
    @br
    @br

    Sampling can also be performed via a @hl.code("UniformDistribution(maximum)"), that generates values uniformly
    distributed between zero and the maximum provided argument.
    Custom domains can be defined using transformations, as in the example below that generates values between -10 and + 10.

     @hl.openmole("""
    val my_input = Val[Double]
    val exploration = ExplorationTask(
        (my_input in (UniformDistribution[Double](max=20) take 100)).map(x => x -10)
    )""", name = "uniform distribution in sensitivity")


    @br



@sect{@shared.otherDoEMenu.LHSSobol }


    High dimension spaces must be handled via specific methods of the literature, because otherwise cartesian product
    would be too memory consuming .
    OpenMOLE includes two of these methods: @a("Sobol Sequence", href:="https://en.wikipedia.org/wiki/Sobol_sequence")
     and  @a("Latin Hypercube Sampling", href:="https://en.wikipedia.org/wiki/Latin_hypercube_sampling") , defined as specifications of the @hl.highlight("ExplorationTask","plain"):
    @br


    @br
    @Resource.rawFrag(Resource.img.sobolLHSID)
    @br
    @b{Method scores:}
    @br

        These two methods perform allright in terms of Input Space Exploration (which is normal as they were built for that extent),
        anyhow, they are superior to uniform sampling or grid sampling, but share the same intrinsic limitations.
        There is no special way of handling Stochasticity of the model, out of standard replications.
        @br
        These methods are not expansive @i{per se} , it depends on the magnitude of the Input Space you want to be covered.
        @hr



    @br@br

     @h3{Latin Hypercube Sampling}


    @hl.openmole("""
    val i = Val[Double]
    val j = Val[Double]

    val my_LHS_sampling =
      ExplorationTask (
        LHS(
          100, // Number of points of the LHS
          i in Range(0.0, 10.0),
          j in Range(0.0, 5.0)
        )
      )
    """, name = "lhs sampling in sensitivity")

    @br

     @h3{Sobol Sequence}

    @hl.openmole("""

    val i = Val[Double]
    val j = Val[Double]

    val my_sobol_sampling =
      ExplorationTask (
        SobolSampling(
          100, // Number of points
          i in Range(0.0, 10.0),
          j in Range(0.0, 5.0)
        )
      )
    """, name = "sobol sampling in sensitivity")





@sect{@shared.otherDoEMenu.severalInputs }
    @p

      Exploration can be performed on several inputs domains, using the @b{cartesian product} operator: @b{x}.
    The basic syntax to explore 2 inputs (i.e. every combination of 2 inputs values) is
       @hl.openmole("""
       val i = Val[Int]
       val j = Val[Double]

       val exploration =
         ExplorationTask (
           (i in (0 to 10 by 2)) x
           (j in (0.0 to 5.0 by 0.5))
         )""", name = "cartesian product for sensitivity")


    @h3{Different Types of inputs}
    @br

    The cartesian product operator can handle different data types :
     @hl.openmole("""
       val i = Val[Int]
       val j = Val[Double]
       val k = Val[String]
       val l = Val[Long]
       val m = Val[File]

       val exploration =
         ExplorationTask (
           (i in (0 to 10 by 2)) x
           (j in (0.0 to 5.0 by 0.5)) x
           (k in List("Leonardo", "Donatello", "Raphaël", "Michelangelo")) x
           (l in (UniformDistribution[Long]() take 10)) x
           (m in (workDirectory / "dir").files().filter(f => f.getName.startsWith("exp") && f.getName.endsWith(".csv")))
         )
        """, name = "data on cartesian product sampling in sensitivity")

    This task performs every combination between the 5 inputs i,j,k,l and m. It can handle several types of inputs :
    Integer (i) , Double (j), Strings (k), Long (l), Files (m).

    @br





    The UniformDistribution[T]() take 10 is a uniform sampling of 10 numbers of the Long type,
    taken in the [Long.MIN_VALUE; Long.MAX_VALUE] domain of the Long native type.



    @br

    Files are explored as items of a list.
     The items are gathered  by the @hl.code("files()") function applied  on the @hl.highlight("dir","plain") directory,
     optionally filtered with any @hl.code("String => Boolean")  functions  such as  @hl.highlight("contains(), startswith(), endswith()", "plain")


     (see  the @a("Java Class String Documentation", href:="https://docs.oracle.com/javase/7/docs/api/java/lang/String.html")
     for more details)


    @br
        If your input is one file among many,  or  a line among a CSV file, use the
        @a("CSVSampling task", href := DocumentationPages.fileExploration.file)
        and @a("FileSampling task", href := DocumentationPages.fileExploration.file)




@sect{@shared.otherDoEMenu.sensitivityAnalysis }
    @p Typical Sensitivity analysis (in a simulation experiment  context) is the study of how the variation of an input
    affect the output(s) of a model. Basically it


    @br
    @Resource.rawFrag(Resource.img.thumbnail_sensitivity)
    @br
    @basicButton("Run", classIs(btn ++ btn_danger))(id := shared.sensitivity.button, stylesheet.svgRunButton(10))


    @br
    @br

    @h3{Prerequisites}

    An embedded model in OpenMOLE (see Step 1 : Model)

    @br



    @h2{Variation of one input}

    @p     The most simple case to consider is to observe the effect of a single input variation on a single output.

        This is achieved by using an @b{exploration task} , who will generate the sequence of values of an input, according to its
        boundaries values and a discretisation step.

    @br

       @hl.openmole("""
    val my_input = Val[Double]

    val exploration =
     ExplorationTask(
       (my_input in (0.0 to 10.0 by 0.5))
      )""", name = "variation of 1 input in sensitivity")


    @br



@sect{@shared.otherDoEMenu.sensitivityFireModel }
    @p
    the @hl.highlight("Fire.nlogo", "plain") model is a simple, one-parameter, simulation model that simulates fire propagation.
    This model features a threshold value in its unique parameter domain, below which fire fails to burn the majority
    of the forest, and beyond which fire propagates and burn most of it.
    We will perform sensitivity analysis to make this threshold appear.
    Sometimes. Stay tuned !
    TODO est ce qu'il faut vaiment le faire ici ou faire un tuto dédié ?
    TODO le faire d'abord et décider ensuite
